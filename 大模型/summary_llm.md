# 大语言模型
代码对应LLMBook页码：数据预处理实践（68），BPE分词（71-73），Mixtral混合专家层（97）<br/>
案例对应LLMBook页码：数据预处理，（79）LLaMA详细配置（97）<br/>
总结：数据准备（数据预处理（过滤去重词元化）+数据调度（数据混合数据课程））——>大规模预训练——>微调与对齐——>下游应用<br/>
## 第一部分 背景与基础知识
### 第一章 引言
#### 语言模型的4个发展阶段
统计语言模型：由若干个连续上下文单词预测下一词的出现概论，但会出现维数灾难<br/>
神经语言模型：神经网络来建模文本序列生成，如RNN等，用词嵌入隐式表达语义特征<br/>
预训练语言模型：如ELMo可根据下游任务对网络进行微调Fine-Tuning,实习面向特定任务的模型优化<br/>
大语言模型：通过规模扩展通常会带来下游任务的模型性能提升，这种现象被称为“扩展法则”<br/>
![1](pics/1.png)

#### 大语言模型技术概览
规模扩展：参数、数据、算力的规模扩展，GPT3有175B参数<br/>
数据工程：对海量文本进行下一词预测的优化，使模型学到丰富语义信息，再用文本补全方式解决各种下游任务，含数据采集、清洗和配比<br/>
高效预训练：参数量大因此需使用大规模分布式训练算法来优化大语言模型神经网络参数，为支持分布式训练需专业框架如DeepSpeed和Megatron-LM，搭建的全栈式优化体系架构能支持大模型预训练数据调度安排。<br/>
能力激发：为提升训练好的模型的任务求解能力，需合适的指令微调以及提示策略进行激发诱导，提示模型在未见任务上的泛化能力，如上下文学习、思维链提示等。<br/>
人类对齐：代表性为3H对齐标准，即有用性、诚实性和无害性，为解决这一问题提出了人类反馈强化学习算法，将人类偏好引入大模型的对齐过程，先训练出能区分模型输出质量好坏的奖励模型，进而用强化学习算法来指导模型输出行为的调整，让语言模型生成符合人类预期的输出。犹豫强化学习算法RLHF优化过程复杂，学术界出现了一批监督微调的对齐方式，从而简化RLHF优化过程，如DPO算法<br/>
工具使用：大语言模型在非自然语言形式的任务能力受限，因此工具学习成为扩展大模型能力的关键技术，让其学会各种工具的调用方法，进而实现特定功能需求，如调用搜索引擎等。<br/>

语言模型的能力特点：具有较为丰富的世界知识，具有较强通用任务解决能力，具有较好的复杂任务推理能力，具有较强人类指令遵循能力，具有较好的人类对齐能力，具有可拓展的工具使用能力。<br/>

大语言模型对科技发展的影响：自然语言处理、信息检索、计算机视觉、人工智能赋能科学研究<br/>
### 第二章 基础介绍
大语言模型是指在海量无标注文本数据上进行预训练得到的大型预训练语言
模型，例如 GPT-3，PaLM和LLaMA。<br/>
#### 大语言模型的构建过程
大语言模型是一种基于Transformer结构的神经网络模型，因此构建其的过程就说使用训练数据对于模型参数的拟合过程，本质是做模型参数的优化，大语言模型的优化目标更加泛化，希望作为通用任务的求解器。<br/>
因此训练过程可分为 大规模预训练 和 指令微调与人类对齐 两个阶段<br/>
1. 大规模预训练<br/>
需准备大规模、高质量、多源化的文本数据，并进行严格的清洗去除掉有毒有害的内容，最后将清洗的数据进行词元化（Tokenization）并切分为批次（Batch）<br/>
目前开源模型普遍采样2-3T规模的词元进行预训练并进一步扩大规模，这一过程算力需求量极高一般训练百亿模型至少需要百卡规模的算力集群（如A100 80G）联合训练数月时间，训练千亿模型则需要千卡甚至万卡规模的算力集群<br/>
而训练中大量需要深入探索的经验性技术如数据如何配比，如何对学习率调整，如何早期发展模型的异常行为等，对核心训练人员能力有巨大考验。<br/>
2. 指令微调（提升任务解决能力）与人类对齐（与人类期望、需求、价值观对齐）<br/>
大规模数据预训练后的语言模型具备了较强的模型能力，但这些模型更擅长文本补全并不适合直接解决具体的任务。<br/>
目前来说较广泛的微调技术是“指令微调”，也叫有监督微调SFT，通过使用任务输入与输出的配对数据进行模型训练，使得模型较好地掌握通过问答形式进行任务求解的能力，这种模仿示例数据进行学习的过程本质属于机器学习中的模仿学习（给定特定任务有多解，模仿学习会加强对于标准答案示范动作的复刻学习）。<br/>
指令微调很难教会大语言模型预训练阶段没学到的知识与能力，主要起了对模型能力的激发作用而不是知识注入<br/>
与与训练相比指令微调数据规模小得多，通常数十万到百万（1-10m量）能有效解决，甚至数千或万条高质量指令数据也能达到不错的微调效果，因此若干台单机八卡（A100-80G）就能在一天或数天时间内完成百亿模型的指令微调。<br/>

与人类对齐中可参照InstructGPT论文，引入基于人类反馈的强化学习对齐方法RLHF，在指令微调后使用强化学习加强模型的对齐能力，在RLHF中需要训练一个符合价值观的奖励模型，为此需要标注人员针对大语言模型所生成的多条输出进行偏好排序并用偏好数据训练奖励模型，用于判断模型输出质量。<br/>
通常强化学习需要维护更多的辅助模型做训练，消耗多于指令微调远小于预训练阶段所需算力，目前一些工作也在消除奖励模型的使用用SFT达到与RLHF相似的效果从而简化过程。<br/> 
#### 扩展法则
大模型的成功关键在于对“规模扩展”的充分探索与利用，大语言模型采用了与小型预训练语言模型相似的网络结构（基于Transformer）和预训练方法（如语言建模），通过扩展参数规模、数据规模和计算算力使LLM能力显著提升，下面介绍两种扩展法则：<br/>
1. KM扩展法则<br/>
模型规模N，数据规模D，计算算力C之间的幂律关系
2. Chinchilla扩展法则<br/>
对指导大语言模型充分利用给定算力资源进行优化训练，对更大范围的模型规模（70M到16B）和数据规模（5B到500B）进行实验，拟合找的另一种关于模型性能的幂律关系。<br/>

总结：<br/>
可预测的扩展：扩展法则可用于通过较小算力资源可靠地估计较大算力资源投入后的模型性能：即小模型预估大模型性能或大模型早期训练性能预测训练完成后性能）<br/>
任务层面可预测性：实践中更关注大语言模型真实任务中的性能提示，如语言建模损失的减少是否意味着真实任务上模型性能的提高。有时可能“逆向扩展”即模型损失降低但任务性能变差。<br/>

#### 涌现能力
即小模型中不存在但在大模型中出现的能力。<br/>
代表性的三种涌现能力：上下文学习ICL（GPT-3正式提出），指令遵循（大模型按照自然语言指令执行对应任务，需做指令微调/又名监督微调），逐步推理（解决复杂任务，可应用思维链提示策略）<br/>

#### 扩展法则和涌现能力
提供两种观点来理解大模型对小模型的优势，扩展法则用语言建模损失来衡量整体性能，提升趋势平滑且可预测；<br/>
涌现能力用任务性能来衡量模型性能，可能出现骤升趋势不可预测，但一旦出现则意味着模型性能大幅提升<br/>
可以类比婴儿学习语言的过程，有可衡量标准也有顿悟阶段。<br/>
#### GPT系列模型技术演变
![2](pics/2.png)<br/>
GPT 系列模型的基本原理是训练模型学习恢复预训练文本数据，将广泛的世
界知识压缩到仅包含解码器（Decoder-Only）的 Transformer 模型中，从而使模型
能够学习获得较为全面的能力。其中，两个关键要素是：（I）训练能够准确预测下
一个词的 Transformer （只包含解码器）语言模型；（II）扩展语言模型的规模以及
扩展预训练数据的规模。<br/>
![3](pics/3.png)<br/>

### 第三章 大语言模型资源
#### 公开可用的模型检查点或API
1. 模型<br/>
LLaMA：13B参数在部分基准测试中超越了175B参数的GPT-3，其在超1T词元的预训练语料上进行了训练，其中65B参数的模型版本在2048张80G的A100GPU上训练了21天，对公众开放且性能优秀，许多研究工作以其为基座模型进行微调或预训练衍生出变体模型<br/>
LLaMA-2：有7B，13B，70B四种参数规模版本且可商用，相比扩充了预训练的词元量达2T，且上下文长度翻倍达到4096个词元，并引入分组查询注意力机制等技术来提升模型性能。此外以此为基座模型完成了“预训练-有监督微调-基于人类反馈的强化学习”这一训练流程，并发布了LLaMA-Chat<br/>
ChatGLM：智谱AI和清华联合开发的中英双语LLM，该系列参数量都是6B，具备流畅对话能力且部署门槛低。<br/>
Falcon：包括7B、40B和180B三个参数版本，7B版本用384张A100使用了1.5T词元进行训练，40B版本的模型在384张A100上使用1T词元训练，180版本模型在4096张A100上使用3.5T词元进行训练，TII也开放了指令微调模型供使用<br/>
Baichuan：百川智能公司发布的开源可商用大语言模型，参数规模7B<br/>
InternLM：上海人工智能实验室开发的多语言开源大模型，已开源7B和20B<br/>
Qwen：阿里的多语大模型系列<br/>
Gemma：谷歌发布的轻量级开源大模型，有2B和7B两种参数规模<br/>
![4](pics/4.png)<br/>
2. API<br/>
公共API：GPT系列、以及文本表征的API<br/>
3. 数据集<br/>
常用预训练数据集：<br/>
![5](pics/5.png)
https://www.gutenberg.org/ebooks/<br/>
https://dumps.wikimedia.org/<br/>
https://huggingface.co/datasets/wikipedia<br/>
![6](pics/6.png)<br/>
![7](pics/7.png)<br/>
4. 代码库<br/>
Hugging Face<br/>
DeepSpeed(微软开发的加速深度学习模型训练的高性能库，与pytorch兼容，广泛用于LLM分布式训练)<br/>
Megatron-LM（NVIDIA开发的专门训练LLM的深度学习代码库，支持数据、模型并行）<br/>
## 第二部分 预训练
### 第四章 数据准备
现有大语言模型预训练数据中各种数据来源：<br/>
![9](pics/9.png)<br/>
##### 数据预处理过程
![8](pics/8.png)<br/>
0. 预训练数据与实践<br/>
数据数量、质量（重复、有偏、有毒、隐私内容）都会污染数据集，影响模型性能<br/>
实践方法：YuLan-GARDEN是一个集成的预训练数据处理框架，包含了支持探测评估数据的分析模块和包含不同粒度算子的数据处理模块，且支持多进程并行处理大规模预训练数据；用户可通过分析模型初步了解数据整体信息，然后通过改配置文件以自定义框架内预定义好的数据处理算子的参数和顺序，形成定制化的数据处理流程<br/>
代码见LLMBook第68页<br/>
1. 质量过滤<br/>
直接收集的文本数据中掺杂了许多低质量数据，两种清洗方法：基于启发式规则的方法和基于分类器的方法<br/>
**基于启发式规则的方法**:通过精心设计的规则来针对地识别和剔除低质量的文本数据，如处理Reddit数据时通过过滤点赞数少的帖子剔除低质量内容，而处理代码语料时可过滤掉非代码相关格式的数据。<br/>
目前常用：基于语种的过滤（特定目标语言），基于简单统计指标的过滤（如句子长度、标点分布、困惑度评估指标删除表达不自然的句子等），基于关键词过滤（对重复高、有攻击性、电话号码等信息过滤）<br/>
**基于分类器的方法**:可训练用于判别数据质量的文本分类器，进行预训练语料的清洗;如可选取代表性数据做标注（标记高质量数据做正样本，低质量数据做负样本），以此训练出一个精准的文本质量分类器<br/>
目前常用：轻量级模型（如FastText）,可微调预训练语言模型（如BERT，LLaMA等）及闭源大模型API。<br/>
为了平衡效率与准确性，可以针对具体数据集合进行清洗策略的灵活组合。例
如，可以首先利用启发式规则进行初步筛选，以快速排除不符合要求的文档，随
后再采用分类器方法进一步精细过滤，确保最终筛选出的语料具有较好的文本质
量。<br/>
2. 敏感内容过滤<br/>
过滤有毒内容：Jigsaw评论数据集提供用于训练毒性分类器的数据，包括有毒、严重有毒、有威胁、侮辱性、暴力、身份仇恨等六个类别，设置合理阈值可训练出分类器并过滤掉有毒的内容信息。<br/>
过滤隐私内容：互联网上内容可能包括敏感信息或可识别的个人信息，直接方法是用启发式方法如关键字识别来删除私人信息<br/>
3. 数据去重<br/>
大语言模型具有较强数据拟合和记忆能力，容易习得数据中重复模式即过度学习，研究发现语料中重复低质量数据可能诱导模型生成时频繁输出类似数据进而影响性能。<br/>
为避免此数据集污染问题，需要从预训练数据集中删除在测试集中可能出现的重复或相关文本，防止训练集测试集重叠，因此算法可基于不同计算粒度以及匹配方法。<br/>
方法有：计算粒度，用于去重的匹配方法（精确匹配算法或近似匹配算法）<br/>
4. 词元化Tokenization（分词）<br/>
旨在将原始文本分割成模型可识别和建模的词元序列，由于中文可能有海量低频词，因此一些模型用字符作为最小单位来分词，最近**子词分词器**被广泛应用于基于transformer的语言模型中，包括BPE分词、WordPiece分词和Unigram分词。<br/>
代码见LLMBook第71页<br/>
（1）BPE分词&字节级别的BPE<br/>
从一组基本符号开始，迭代地寻找语料库中两个相邻词元并将其替换为新词元（合并）<br/>
（2）WordPiece分词(与BPE类似，迭代合并连续的词元)<br/>
区别是标准略有不同，合并前会首先训练一个语言模型，并用其对所有可能的词元进行评分，每次合并时选择使得训练数据的似然性增加最多的词元对<br/>
（3）Unigram分词<br/>
从足够大的字符串或词元初始集合开始，迭代的删除其中词元至达到语气词表大小<br/>
（0）分词器的选用<br/>
关注几个因素：分词器具备无所重构的特性（无误还原原始文本），高压缩率（分词后词元尽可能少，用压缩率计算衡量）<br/>
5. **数据调度**<br/>
完成预处理后需设计合适的调度策略来安排这些多来源的数据，进而用于训练大语言模型，通常数据调度关注两个方面：各个数据源混合比例以及各数据源用于训练的顺序<br/>
![10](pics/10.png)<br/>
（1）数据混合<br/>
设置合适的混合比例十分重要，可在不同阶段采用不同混合数据比例，预训练期间根据混合比例从不同数据源中采样数据<br/>
数据混合策略（基于经验）：增加数据源的多样性（网页、书籍、代码）、优化数据混合（除手动设置数据混合配比外还可使用可学习的方法来优化数据组成，如根据下游任务选择特征空间相似的预训练数据或可对下游任务产生正面影响的数据）、优化特定能力（如使用更多数学文本和代码增加模型推理能力）<br/>
（2）数据课程<br/>
指按照特定的顺序安排预训练数据进行模型的训练，例如从简单通用的数据开始，逐渐引入更具挑战性/专业化的数据，即训练的不同阶段使用不同的数据源配比。<br/>
一种实用方法是基于专门构建的评测基准监控大语言模型的关键能力的学习过程，然后在预训练期间动态调整数据的混合配比<br/>
以三种常见能力为例介绍数据课程在继续预训练中的应用：<br/>
代码能力、数学能力、长文本能力<br/>

### 第五章 模型架构
![11](pics/11.png)<br/>
#### 5.1 Transformer模型
多层多头自注意力模块堆叠而成的神经网络模型，由编码器（可架构为BERT）解码器（可架构为GPT）两部分组成。<br/>
1. 输入编码<br/>
词元序列u=[u1,u2...ut]经过输入嵌入模块（embedding）转化为词向量序列，一个词元被映射成一个固定维度的词向量vt<br/>
引入位置编码表示序列中位置信息，给定一个词元ut位置编码根据其绝对位置分配一个嵌入向量pt并直接相加生成最终输入嵌入序列X=[x1,...xT]<br/>
2. 多头自注意力机制<br/>
该机制能直接建模任意距离的词元之间交互关系，由多个自注意力模块组成<br/>
每个模块中，将输入词元序列映射为QKV三个矩阵，然后Q对未掩盖的K做点积，并将值除以根号D缩放（D是键对应的向量维度），传入softmax中计算权重，将权重作用于值，通过加权和形式计算得输出<br/>
多注意力即多个头的组合拼接在一起，由一个权重阵Wo映射；每个“头”含一个查询、键、值<br/>
3. 前馈网络层FFN<br/>
由两个线性变换和一个非激活函数组成<br/>
![12](pics/12.png)<br/>
4. 编码器<br/>
作用是将每个输入词元编码成一个上下文语义相关的表示向量；<br/>
注意力和前馈网络后使用层归一化(对数据重新放缩提升模型训练稳定性)和残差连接(输入与该层输出相加缓解梯度爆炸)来加强模型的训练稳定度<br/>
自注意力使用双向注意力，每个位置词元能够有效融合上下文语义信息<br/>
5. 解码器<br/>
引入掩码自注意力模块，计算注意力分数时遮掩当前位置之后的词，保证目标不依赖未来信息<br/>
训练过程中通过一次前向传播让每个词元预测下一个词元；解码时需逐步生成，自回归地生成完整目标序列<br/>

#### 5.2 详细配置
Transformer四个核心组件配置：归一化、位置、激活函数、注意力机制<br/>
1. 归一化方法<br/>
为了解决LLM预训练中不稳定的问题，采用特定归一化策略来加强神经网络训练过程稳定性<br/>
原始Transformer使用了层归一化（LN，减均值除以方差），后来有了均方根归一化（RMSNorm，仅利用均方根对激活值重新缩放，加快训练速度）DeepNorm（稳定深层训练，在LN基础上对激活值x按照比例放缩，以此扩展transformer层数，提升模型性能与训练稳定性）这些技术。<br/>
2. 归一化模型位置<br/>
三种选择：层后归一化（先残差再归一化），层前归一化（每个子层前进行再做残差）和夹心归一化（残差之前，但有时易训练崩溃）<br/>
3. 激活函数<br/>
为了神经网络中引起非线性变化，提升网络的模型能力<br/>
ReLU(x)=max(x,0),简单但被置0的神经元学习不到有用信息<br/>
Swish激活函数将神经元和其sigmoid激活的乘积作为新激活函数<br/>
GELU则用标准高斯累计分布函数做激活函数，相比传统ReLU新的激活函数能带来更好的性能和收敛性，但计算更复杂<br/>
GLU和SwiGLU激活函数也被用于PaLM和LaMDA等LLM中，其引入两个不同线性层一个线性层输出被输入到一个激活函数中，其结果将和另一个线性层输出逐元素相乘作为最终输出<br/>
![13](pics/13.png)<br/>
4. 位置编码<br/>
Transformer中自注意力模块具有置换不变性，因此仅用注意力机制无法捕捉序列中顺序关系，因此引入位置编码PE<br/>
绝对位置编码，相对位置编码，旋转位置编码,ALiBi位置编码（详细公式略）<br/>
5. 注意力机制<br/> 
完整注意力机制，稀疏注意力机制，多查询/分组查询注意力，硬件优化的注意力机制<br/>
6. 混合专家模型<br/>
旨在不显著提升计算成本的同时实现对模型参数的拓展<br/>
混合专家模型含K个专家组件，每个都是前馈神经网络，先由路由网络计算各专家权重，然后选出K个得分最高专家进行激活其余权重置为0，最后输出加权作为最终输出。<br/>
代表性混合专家模型是Mixtral(8×7B)，每个词元选两个专家做后续计算<br/>

#### 5.3 主流框架
编码器架构：BERT为代表<br/>
解码器架构：GPT为代表<br/>
编码器-解码器架构：T5<br/>
解码器架构的变种：因果解码器，前缀解码器<br/>
![14](pics/14.png)<br/>
绝大部分主流的大语言模型采用了**因果解码器**架构。因果解码器采用
了 Transformer 中的解码器组件，同时做出了几点重要改动。首先，因果解码器没
有显式地区分输入和输出部分。如图 5.6 所示，该架构采用了单向的掩码注意力机
制，使得每个输入的词元只关注序列中位于它前面的词元和它本身，进而自回归
地预测输出的词元。此外，由于不含有编码器部分，因果解码器删除了关注编码
器表示的交叉注意力模块。经过自注意力模块后的词元表示将直接送入到前馈神
经网络中。在因果解码器架构中，最具有代表性的模型就是 OpenAI 推出的 GPT
系列。其中，GPT-3 将模型参数拓展到了 100B 级别，并展现出了强大的零样本和
少样本学习能力。伴随着 GPT-3 的成功，因果解码器被广泛采用于各种大语言模
型中，包括 BLOOM、LLaMA 和 Mistral 等。<br/>
**前缀解码器**对于输入（前缀）部分使用双向注意力进行编码，而对于输出
部分利用单向的掩码注意力利用该词元本身和前面的词元进行自回归地预测。与
编码器-解码器不同的是，前缀解码器在编码和解码过程中是共享参数的，并没有
划分为独立的解码器和编码器。对于前缀解码器，也可以由现有的因果解码器继
续预训练转换而来，进而加速该模型的训练。例如，U-PaLM 是从 PaLM [33]
继续预训练而来的。当前，基于前缀解码器架构的代表性大语言模型包括 GLM-
130B 和 U-PaLM。<br/>
#### 5.4 上下文模型
为了支持长文本处理，多家机构均已推出面向具有超长上下文窗口的大
语言模型或 API。例如，OpenAI 发布了支持 128K 上下文窗口的 GPT-4 Turbo，而
Anthropic 则推出了具有 200K 上下文窗口的 Claude-2.1<br/>
增强大语言模型长文本建模能力的研究集中在两个方向：扩展位置编码和调整上下文窗口<br/>
1. 扩展位置编码：略
2. 调整上下文窗口：略

#### 5.5 新型架构模型
![15](pics/15.png)

### 第六章 模型预训练
#### 6.1 预训练任务
常用的预训练技术共三类：<br/>
1. 语言建模LM<br/>
本质是预测下一个词元，每次损失都计入总损失<br/>
变种是**前缀语言建模PLM**，专门采样5.3节的前缀解码器而设计，训练阶段每个文本序列根据随机选择的位置k切分为前缀后缀两部分，在前缀解码器中仅后缀中的词元会被计入总损失，本质是基于前缀信息预测后缀词元<br/>
另一变种是**中间填充任务**，划分为前缀中间部分和后缀，随后中间部分被移至序列末尾，模型自回归地对新序列进行预测，提升填充中间缺失信息的能力<br/>

2. 去噪自编码DAE<br/>
输入文本经过一系列随即替换或删除操作，形成损坏的文本，模型目标是根据损坏的文本恢复除被替换或删除的词元片段<br/>

3. 混合去噪器<br/>
通过将语言建模和去噪自编码的目标均视为不同类型的去噪任务，对于预训练任务进行了统一建模。具体来说，混合去噪
器定义了三种去噪器：S-去噪器、R-去噪器和 X-去噪器。<br/>
S-去噪器与前缀语言建模的目标相同，旨在训练模型学习
基于给定前缀信息生成合理的后缀文本的能力。相比之下，R-去噪器和 X-去噪器
与去噪自编码任务的优化目标更为相似。二者仅仅在被掩盖片
段的跨度和损坏比例上有所区别。R-去噪器屏蔽序列中约 15% 的词元，且每个被
屏蔽的片段仅包含 3 到 5 个词元。而 X-去噪器则采用更长的片段（12 个词元以上）
或更高的损坏比例（约 50%），进而要求模型能够精准还原原始信息。这种设置增
加了任务难度，迫使模型学习到更全面的文本表示。<br/>
为了引导模型针对不同类型的输入选择相应的去噪器，输入句子会以特殊词
元（如 [R], [S], [X]）作为开头。这种标记方式引导模型识别输入中使用的去噪
器，并对该去噪器损坏的词元进行还原。<br/>
混合去噪器被应用于训练 UL2和 PaLM 2 等大语言模型。<br/>
#### 6.2 训练优化设置
训练批次<br/>
![16](pics/16.png)
学习率：先线性上升后降（线性衰减、余弦衰减、平方根倒数衰减）<br/>
优化器：Adam(使用梯度的‘动量’作为参数更新方向)或其变种AdamW<br/>
稳定优化技术（应对训练不稳定问题）：梯度裁剪（梯度的模长超过给定阈值1.0后截断），训练恢复（避免训练异常，每隔固定步数设置存档点可重启），权重衰减（正则化技术稳定训练过程），Dropout（随机将神经元输出值置零避免过拟合）
#### 6.3 高效可扩展技术
1. 3D并行训练<br/>
数据并行+流水线并行+张量并行<br/>
2. 激活重计算<br/>

3. 混合精度计算<br/>

#### 6.4 效率分析

#### 6.5 代码实践

## 第三部分 微调与对齐
### 第七章 指令微调

### 第八章 人类对齐

## 第四部分 大模型应用
### 第九章 解码与部属

### 第十章 提示学习

### 第十一章 规划与智能体

## 第五部分 评测与应用
### 第十二章 评测

### 第十三章 应用



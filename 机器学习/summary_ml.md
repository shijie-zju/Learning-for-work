# 机器学习-周志华西瓜书总结
## 序论
科学：是什么为什么<br/>
技术：怎么做<br/>
工程：做的多快好省<br/>
应用：技术用于各种方面的总结<br/>

机器学习：利用经验（数据）改善系统性能<br/>
学习过程：训练数据（特征+标签）——训练（学习算法）——>模型（如决策树、神经网络）<br/>
计算学习理论-PAC 概论近似正确：判断f(x)与实际y之差尽可能小，但不是每次都能得到最小(因为对象不是确定精确的，用很高的概论得到很好的模型)，因此希望得到这个差特别小的概率要尽可能地大<br/>
基本术语：数据集（训练、测试），（独立同分布）样本（属性->属性空间，特征->特征向量；标记->标记空间）、分类，回归，（无）监督学习，泛化<br/>
算法的归纳偏好（相信哪个模型是更好的）：奥卡姆剃刀（若非必要勿增实体）<br/>
NFL定理：一个算法a若在某些问题上比另一个算法b好，比存在b比a好的问题<br/>

## 模型评估
泛化能力：用于衡量模型好坏，可用下面两个指标衡量：<br/>
泛化误差：在“未来”样本上的误差<br/>
经验误差：在训练即上的误差，也称“训练误差”<br/>
但二者不一定是越小越好，因为容易出现过拟合，模型拟合程度随着训练先降（欠拟合减弱）后升（转为过拟合），对此至今没有完美解决方案：<br/>
过拟合：学的太多，模型复杂度>>数据特征量<br/>
欠拟合：没学到啥，模型复杂度<<数据特征量<br/>
因此确定三个关键问题：评估方法（获得模型的测试结果）、性能度量（对任务想达到什么效果）和比较检验（统计意义上模型好不好）<br/>
评估方法（即如何获得测试集，也需多次划分每次得一评估值）:留出法（直接切分训练测试集，注意保持数据分布一致性，即训练集测试集中正负样本比例相近如分层采样）、k折交叉验证法（1个子集测试其余训练，做K次，k=m则为留一法）、自助法（有放回采样、可重复采样，即N个样本有放回地抽N次，未抽出的做测试集，缺点是数据正负样本分布改变了）<br/>
超调参（调参数就说模型选择的过程）和验证集（训练集中专门留出用来调参数的部分，**参数选定后，用“训练集+验证集”重新训练最终模型**）<br/>
性能度量（衡量模型泛化性能的评价标准）：回归常用均方误差E=Σ(f(x)-y)^2\m；分类常用错误率、精度、TP、FN、FP、TN，查准率P、查全率R、F1度量<br/>
比较检验（得到某度量下评估结果不可直接判优劣，因为测试性能不等于泛化性能，随机性！）：因为追求概论近似正确，因此用假设检验思想：交叉验证t检验或McNemar检验<br/>











